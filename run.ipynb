{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283e66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import utils\n",
    "import witg\n",
    "import model\n",
    "import dataset\n",
    "import trainer\n",
    "import grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61cf56d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data file\n",
    "data_file  = './dataset/home.txt'\n",
    "\n",
    "# Training sequence file and Weight Item Transition Graph (WITG) file\n",
    "train_sequence_file = './dataset/all_train_seq.txt'\n",
    "witg_file = './dataset/witg.pt'\n",
    "\n",
    "# Splited dataset files\n",
    "train_file = './dataset/train.pkl'\n",
    "valid_file = './dataset/valid.pkl'\n",
    "test_file  = './dataset/test.pkl'\n",
    "\n",
    "# Model checkpoint file\n",
    "output_dir = 'output/'\n",
    "checkpoint_file = output_dir + 'checkpoint.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4467afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f'{output_dir} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aefe3d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('Using GPU')\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b85e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재현성을 위한 시드 설정\n",
    "seed = 2026\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "115eb55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users: 66519, num_items: 28238\n"
     ]
    }
   ],
   "source": [
    "user_num, item_num, train_matrix, test_matrix = utils.get_matrix_and_num(data_file)\n",
    "print(f'num_users: {user_num}, num_items: {item_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8093a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open(train_file, 'rb'))\n",
    "valid_data = pickle.load(open(valid_file, 'rb'))\n",
    "test_data  = pickle.load(open(test_file , 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0053ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading WITG from ./dataset/witg.pt\n",
      "WITG structure       : Data(x=[28238, 1], edge_index=[2, 1617638], edge_attr=[1617638, 1])\n",
      "Answer WITG structure: Data(x=[28238, 1], edge_index=[2, 1617638], edge_attr=[1617638, 1])\n",
      "\n",
      "--- WITG SANITY CHECK ---\n",
      "Number of nodes: Match (28238)\n",
      "Edge connectivity structure: Match\n",
      "Edge weights: Match\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(witg_file):\n",
    "    print(f'Loading WITG from {witg_file}')\n",
    "    global_graph = torch.load(witg_file, weights_only=False)\n",
    "else:\n",
    "    print(f'Building WITG and saving to {witg_file}')\n",
    "    global_graph = witg.build_weighted_item_transition_graph(train_sequence_file=train_sequence_file)\n",
    "    torch.save(global_graph, witg_file)\n",
    "\n",
    "\n",
    "# 만든 WITG를 정답 WITG와 비교합니다.\n",
    "answer_witg = torch.load('./dataset/answer_witg.pt', weights_only=False)\n",
    "print(f\"WITG structure       : {global_graph}\")\n",
    "print(f\"Answer WITG structure: {answer_witg}\")\n",
    "grade.grade_witg(student_graph=global_graph, answer_graph=answer_witg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3662ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위클리 미션 임을 감안하여, epoch는 1로 설정하여 테스트합니다.\n",
    "# 결과 비교를 위해서, 하이퍼 파라미터는 조정하지 않아야 합니다!\n",
    "epochs = 1  \n",
    "batch_size = 2048\n",
    "hidden_size = 64\n",
    "max_seq_length = 50\n",
    "num_hidden_layers = 2\n",
    "num_attention_heads = 2\n",
    "sample_size = [20, 20]\n",
    "lam1 = 1.0\n",
    "lam2 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7da8500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.GCL4SR(\n",
    "    user_num=user_num,\n",
    "    item_num=item_num,\n",
    "    global_graph=global_graph,\n",
    "    hidden_size=hidden_size,\n",
    "    max_seq_length=max_seq_length,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    num_attention_heads=num_attention_heads,\n",
    "    sample_size=sample_size,\n",
    "    lam1=lam1,\n",
    "    lam2=lam2\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ffb8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위클리 미션 임을 감안하여, Validation 단계는 생략합니다.\n",
    "\n",
    "# valid_dataset = dataset.GCL4SRData(valid_data, max_seq_length)\n",
    "# valid_sampler = SequentialSampler(valid_dataset)\n",
    "# valid_dataloader = DataLoader(valid_dataset, sampler=valid_sampler, batch_size=batch_size)\n",
    "\n",
    "train_dataset = dataset.GCL4SRData(train_data, max_seq_length)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size, pin_memory=True, num_workers=8)\n",
    "\n",
    "test_dataset = dataset.GCL4SRData(test_data, max_seq_length)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "500822eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = trainer.Trainer(model, optimizer, sample_size, hidden_size, train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe93663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/GCL4SR/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Epoch 0:   1%|          | 1/172 [00:12<35:07, 12.32s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    loss_list = trainer.train_step(epoch, train_dataloader)\n",
    "    torch.save(model.state_dict(), checkpoint_file)\n",
    "\n",
    "# Loss 값을 비교합니다.\n",
    "grade.grade_loss(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90622f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.load_state_dict(torch.load(checkpoint_file))\n",
    "recall_10, recall_20, ndcg_10, ndcg_20 = trainer.eval_step(test_dataloader, test_matrix)\n",
    "\n",
    "# Evaluation 결과를 비교합니다.\n",
    "grade.grade_eval(recall_10, recall_20, ndcg_10, ndcg_20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GCL4SR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
