{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c71d08b1",
   "metadata": {},
   "source": [
    "# [Weekly Mission] w4_RecSys_Trend_Implement **GCL4SR**\n",
    "\n",
    "\n",
    "## 문제정의\n",
    "저희는 RecSys Trend 강의에서 다음과 같은 내용을 배웠습니다!\n",
    "\n",
    "**Graph-based RecSys**\n",
    "- 추천에서 사용되는 데이터를 유저-아이템 상호작용 그래프로 구성하여 GCN 구조를 사용한 추천 모델을 설계할 수 있다.\n",
    "- 특히, SGL (SIGIR 21)은 Graph Contrastive Learning을 사용하여 추천의 성능을 향상시켰다.\n",
    "\n",
    "**Sequential RecSys**\n",
    "- 유저가 상호작용한 아이템은 그 순서 정보가 존재하며, 이를 활용하면 더 좋은 추천 결과를 얻을 수 있다.\n",
    "- 이를 위해, Transformer와 같은 모델을 사용해서 Sequential 정보를 사용하도록 모델을 설계한다.\n",
    "\n",
    "Graph-enhanced Sequential Recommendation는 위 두 가지 접근법을 적절히 융합하여,\n",
    "그래프로 표현되는 유저-아이템 사이의 연결관계 정보와, 개별 유저가 상호작용한 아이템의 순서 정보를 동시에 활용할 수 있도록 하는 방법론입니다. 이번 위클리 미션에서는 Graph-enhanced Sequential Recommendation 모델 중 하나인 **GCL4SR** (IJCAI 22) 모델의 일부를 구현해볼 것이며, 이를 통해 Graph-based 모델의 강점을 어떻게 Sequential로 녹일 수 있는지, 그리고 추천시스템 학습 및 평가에서 사용되는 전반적인 코드 구조를 이해해보는 것이 목표입니다!\n",
    "\n",
    "**GCL4SR**에 대한 세부내용은 보충자료와 논문 참고 부탁드립니다.\n",
    "\n",
    "---\n",
    "\n",
    "논문 : Enhancing Sequential Recommendation with Graph Contrastive Learning (IJCAI 22) [link](https://www.ijcai.org/proceedings/2022/0333.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a7e4f",
   "metadata": {},
   "source": [
    "## 라이브러리 임포트\n",
    "```bash\n",
    "torch >= 2.7\n",
    "torch-geometric >= 2.6.1\n",
    "torch_sparse >= 0.6.18\n",
    "torch_scatter >= 2.1.2\n",
    "numpy >= 2.2.6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "283e66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from torch import nn, Tensor\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.init import xavier_normal_, constant_\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "from torch_geometric.nn import SAGEConv, GCNConv\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "from numpy import lexsort\n",
    "\n",
    "from typing import List, Tuple, Dict, Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80e156d",
   "metadata": {},
   "source": [
    "## 환경 설정\n",
    "데이터셋은 첨부 파일을 확인해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f075fb33",
   "metadata": {},
   "source": [
    "### 데이터셋 경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61cf56d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data file\n",
    "data_file  = './dataset/home.txt'\n",
    "\n",
    "# Training sequence file and Weight Item Transition Graph (WITG) file\n",
    "train_sequence_file = './dataset/all_train_seq.txt'\n",
    "witg_file = './dataset/witg.pt'\n",
    "\n",
    "# Splited dataset files\n",
    "train_file = './dataset/train.pkl'\n",
    "valid_file = './dataset/valid.pkl'\n",
    "test_file  = './dataset/test.pkl'\n",
    "\n",
    "# Model checkpoint file\n",
    "output_dir = 'output/'\n",
    "checkpoint_file = output_dir + 'checkpoint.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4467afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f'{output_dir} created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d6f8b5",
   "metadata": {},
   "source": [
    "### GPU 사용 여부 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aefe3d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('Using GPU')\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2724f8b3",
   "metadata": {},
   "source": [
    "### 재현성을 위한 시드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29b85e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재현성을 위한 시드 설정\n",
    "seed = 2026\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2691725",
   "metadata": {},
   "source": [
    "### 기타 유틸리티 함수 및 클래스 선언 (수정 금지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50d2ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rating_matrix_train(user_seq, num_users, num_items):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    for user_id, item_list in enumerate(user_seq):\n",
    "        for item in item_list[:-2]: #\n",
    "            row.append(user_id)\n",
    "            col.append(item)\n",
    "            data.append(1)\n",
    "\n",
    "    row = np.array(row)\n",
    "    col = np.array(col)\n",
    "    data = np.array(data)\n",
    "    rating_matrix = csr_matrix((data, (row, col)), shape=(num_users, num_items))\n",
    "\n",
    "    return rating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe5f75cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rating_matrix_test(user_seq, num_users, num_items):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    for user_id, item_list in enumerate(user_seq):\n",
    "        for item in item_list[:-1]: #\n",
    "            row.append(user_id)\n",
    "            col.append(item)\n",
    "            data.append(1)\n",
    "            \n",
    "    row = np.array(row)\n",
    "    col = np.array(col)\n",
    "    data = np.array(data)\n",
    "    rating_matrix = csr_matrix((data, (row, col)), shape=(num_users, num_items))\n",
    "\n",
    "    return rating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b028e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_and_num(data_file):\n",
    "    lines = open(data_file).readlines()\n",
    "    user_seq = []\n",
    "    item_set = set()\n",
    "    for line in lines:\n",
    "        user, items = line.strip().split(' ', 1)\n",
    "        items = items.split(',')\n",
    "        items = [int(item) for item in items]\n",
    "        user_seq.append(items)\n",
    "        item_set = item_set | set(items)\n",
    "    max_item = max(item_set)\n",
    "\n",
    "    num_users = len(lines)\n",
    "    num_items = max_item + 1\n",
    "\n",
    "    train_matrix = generate_rating_matrix_train(user_seq, num_users, num_items)\n",
    "    test_matrix = generate_rating_matrix_test(user_seq, num_users, num_items)\n",
    "    return num_users, num_items, train_matrix, test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e32dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCL4SRData(Dataset):\n",
    "    def __init__(self, data, max_seq_length):\n",
    "        self.max_len = max_seq_length\n",
    "        self.data = data\n",
    "        self.uid_list = data[0]\n",
    "        self.part_sequence = data[1]\n",
    "        self.part_sequence_target = data[2]\n",
    "        self.part_sequence_length = data[3]\n",
    "        self.length = len(data[0])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_ids = self.part_sequence[index]\n",
    "        target_pos = self.part_sequence_target[index]\n",
    "        user_id = self.uid_list[index]\n",
    "\n",
    "        pad_len = self.max_len - len(input_ids)\n",
    "        input_ids = [0] * pad_len + input_ids\n",
    "\n",
    "        input_ids = input_ids[-self.max_len:]\n",
    "\n",
    "        cur_tensors = (\n",
    "            torch.tensor(user_id, dtype=torch.long),\n",
    "            torch.tensor(input_ids, dtype=torch.long),\n",
    "            torch.tensor(target_pos, dtype=torch.long),\n",
    "        )\n",
    "        return cur_tensors\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be46bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_witg(student_graph: Data, answer_graph: Data):\n",
    "    print(\"\\n--- WITG SANITY CHECK ---\")\n",
    "    \n",
    "    if student_graph.num_nodes == answer_graph.num_nodes:\n",
    "        print(f\"Number of nodes: Match ({student_graph.num_nodes})\")\n",
    "    else:\n",
    "        print(f\"Number of nodes: Mismatch (Student: {student_graph.num_nodes}, Answer: {answer_graph.num_nodes})\")\n",
    "\n",
    "    try:\n",
    "        # Sort student graph edges\n",
    "        student_perm = lexsort(keys=(student_graph.edge_index[1].cpu().numpy(), student_graph.edge_index[0].cpu().numpy()))\n",
    "        student_sorted_edges = student_graph.edge_index[:, student_perm]\n",
    "        student_sorted_attrs = student_graph.edge_attr[student_perm]\n",
    "\n",
    "        # Sort answer graph edges\n",
    "        answer_perm = lexsort(keys=(answer_graph.edge_index[1].cpu().numpy(), answer_graph.edge_index[0].cpu().numpy()))\n",
    "        answer_sorted_edges = answer_graph.edge_index[:, answer_perm]\n",
    "        answer_sorted_attrs = answer_graph.edge_attr[answer_perm]\n",
    "\n",
    "        # Compare edge structures\n",
    "        if torch.equal(student_sorted_edges, answer_sorted_edges):\n",
    "            print(\"Edge connectivity structure: Match\")\n",
    "        else:\n",
    "            print(\"Edge connectivity structure: Mismatch\")\n",
    "\n",
    "        # Compare edge attributes (weights)\n",
    "        if torch.allclose(student_sorted_attrs, answer_sorted_attrs):\n",
    "            print(\"Edge weights: Match\")\n",
    "        else:\n",
    "            print(\"Edge weights: Mismatch\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during edge comparison: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "975385d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_loss(student_loss):\n",
    "    answer_loss = (9.9495, 15.3257, 0.2743)\n",
    "    ans_main_loss, ans_gcl_loss, ans_mmd_loss = answer_loss\n",
    "    \n",
    "    try:\n",
    "        stu_main_loss, stu_gcl_loss, stu_mmd_loss = student_loss\n",
    "        float(stu_main_loss), float(stu_gcl_loss), float(stu_mmd_loss)\n",
    "    except (TypeError, ValueError):\n",
    "        print(\"\\n--- LOSS SANITY CHECK FAILED ---\")\n",
    "        print(\"Error: student_loss must contain three numerical values.\")\n",
    "        print(f\"Received input: {student_loss}\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- LOSS SANITY CHECK ---\")\n",
    "    print(\"Loss 값은 GPU 하드웨어에 따라 약간에 오차가 발생할 수 있습니다. 이는 감안하여 채점할 것이니 걱정하지 않으셔도 됩니다.\")\n",
    "    print(\"이 함수는 구현이 잘되었는지 간단히 확인하는 용도로 제공하는 함수입니다!\")\n",
    "\n",
    "    TOLERANCE = 1e-3\n",
    "\n",
    "    if math.isclose(ans_main_loss, stu_main_loss, rel_tol=TOLERANCE):\n",
    "        print(f\"Main Loss: Match (Answer: {ans_main_loss:.4f}, Student: {stu_main_loss:.4f})\")\n",
    "    else:\n",
    "        print(f\"Main Loss: Mismatch (Answer: {ans_main_loss:.4f}, Student: {stu_main_loss:.4f})\")\n",
    "\n",
    "    if math.isclose(ans_gcl_loss, stu_gcl_loss, rel_tol=TOLERANCE):\n",
    "        print(f\"GCL Loss:  Match (Answer: {ans_gcl_loss:.4f}, Student: {stu_gcl_loss:.4f})\")\n",
    "    else:\n",
    "        print(f\"GCL Loss:  Mismatch (Answer: {ans_gcl_loss:.4f}, Student: {stu_gcl_loss:.4f})\")\n",
    "\n",
    "    if math.isclose(ans_mmd_loss, stu_mmd_loss, rel_tol=TOLERANCE):\n",
    "        print(f\"MMD Loss:  Match (Answer: {ans_mmd_loss:.4f}, Student: {stu_mmd_loss:.4f})\")\n",
    "    else:\n",
    "        print(f\"MMD Loss:  Mismatch (Answer: {ans_mmd_loss:.4f}, Student: {stu_mmd_loss:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4c8f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_eval(recall_10: float, recall_20: float, ndcg_10: float, ndcg_20: float):\n",
    "    answer_metrics = {\n",
    "        \"Recall@10\": 0.0082,\n",
    "        \"Recall@20\": 0.0143,\n",
    "        \"NDCG@10\":   0.0040,\n",
    "        \"NDCG@20\":   0.0056\n",
    "    }\n",
    "\n",
    "    student_metrics = {\n",
    "        \"Recall@10\": recall_10,\n",
    "        \"Recall@20\": recall_20,\n",
    "        \"NDCG@10\":   ndcg_10,\n",
    "        \"NDCG@20\":   ndcg_20\n",
    "    }\n",
    "    print(\"\\n--- EVALUATION METRICS SANITY CHECK ---\")\n",
    "    print(\"마찬가지로 Metric 값도 GPU 하드웨어에 따라 약간에 오차가 발생할 수 있습니다. 이는 감안하여 채점할 것이니 걱정하지 않으셔도 됩니다.\")\n",
    "    print(\"이 함수는 구현이 잘되었는지 간단히 확인하는 용도로 제공하는 함수입니다!\")\n",
    "\n",
    "    TOLERANCE = 1e-3\n",
    "\n",
    "    for metric_name, ans_value in answer_metrics.items():\n",
    "        stu_value = student_metrics[metric_name]\n",
    "        display_name = f\"{metric_name}:\".ljust(12)\n",
    "        if math.isclose(ans_value, stu_value, rel_tol=TOLERANCE):\n",
    "            print(f\"{display_name} Match   (Answer: {ans_value:.4f}, Student: {stu_value:.4f})\")\n",
    "        else:\n",
    "            print(f\"{display_name} Mismatch (Answer: {ans_value:.4f}, Student: {stu_value:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3f7544",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "115eb55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users: 66519, num_items: 28238\n"
     ]
    }
   ],
   "source": [
    "user_num, item_num, train_matrix, test_matrix = get_matrix_and_num(data_file)\n",
    "print(f'num_users: {user_num}, num_items: {item_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8093a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open(train_file, 'rb'))\n",
    "valid_data = pickle.load(open(valid_file, 'rb'))\n",
    "test_data  = pickle.load(open(test_file , 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4274ef96",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ec8f4ac",
   "metadata": {},
   "source": [
    "## TODO1: Weighted Item Transition Graph (WITG) 구성하기  \n",
    "\n",
    "논문에 제시된 WITG 구성 방법을 구현하는 함수 `build_weighted_item_transition_graph`를 완성해주세요.  \n",
    "이를 위해서, `read_item_sequences`, `convert_to_pyg_data` 함수의 입출력을 살펴보아야 합니다.  \n",
    "WITG 구성 방법은 수식으로 보면 아래와 같습니다.\n",
    "\n",
    "- $k= 1, 2, 3$ : window size  \n",
    "- $1/k$ : 노드 $v_t$가 노드 $v_{t+k}$에 영향을 미치는 점수  \n",
    "\n",
    "$$\n",
    "w(v_t, v_{t+k}) = \\begin{cases}\n",
    "1/k & \\text{if }v_t, v_{t+k}\\text{를 연결하는 엣지가 WITG에 없는 경우} \\\\\n",
    "w(v_t, v_{t+k}) + 1/k & \\text{if }v_t, v_{t+k}\\text{를 연결하는 엣지가 이미 WITG에 있는 경우}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9620e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_item_sequences(file_path: str) -> Tuple[List[List[int]], int]:\n",
    "    \"\"\"\n",
    "    사용자별 아이템 시퀀스 파일을 읽어 파싱합니다.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): 'user_id item1,item2,...' 형식의 텍스트 파일 경로.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[List[int]], int]: \n",
    "            - 모든 사용자의 아이템 시퀀스 목록 (e.g., [[1,2,3], [4,5]])\n",
    "            - (가장 큰 아이템 ID + 1)을 의미하는 전체 노드 개수\n",
    "    \"\"\"\n",
    "    user_sequences = []\n",
    "    all_items = set()\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # \"user_id item1,item2,...\" -> [\"user_id\", \"item1,item2,...\"]\n",
    "            _, items_str = line.strip().split(' ', 1)\n",
    "            items = [int(item) for item in items_str.split(',')]\n",
    "            \n",
    "            user_sequences.append(items)\n",
    "            all_items.update(items)\n",
    "\n",
    "    num_nodes = max(all_items) + 1 if all_items else 0\n",
    "    return user_sequences, num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c642fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pyg_data(adjacency_list: List[Dict[int, float]], num_nodes: int) -> Data:\n",
    "    \"\"\"\n",
    "    인접 리스트 형태의 그래프를 PyTorch Geometric(PyG)의 Data 객체로 변환합니다.\n",
    "\n",
    "    Args:\n",
    "        adjacency_list (List[Dict[int, float]]): \n",
    "            - 그래프의 인접 리스트. \n",
    "            - e.g., adj[source_node] = {target_node_1: weight_1, ...}\n",
    "        num_nodes (int): 그래프의 전체 노드 개수.\n",
    "\n",
    "    Returns:\n",
    "        Data: PyG 모델에서 사용할 수 있는 그래프 데이터 객체.\n",
    "    \"\"\"\n",
    "    edge_list = []\n",
    "    weight_list = []\n",
    "\n",
    "    # 각 노드에 대해, 이웃 노드들을 가중치(weight)가 높은 순으로 정렬\n",
    "    for source_node, neighbors in enumerate(adjacency_list):\n",
    "        # neighbors.items() -> [(target_node, weight), ...]\n",
    "        sorted_neighbors = sorted(neighbors.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "        for target_node, weight in sorted_neighbors:\n",
    "            edge_list.append([source_node, target_node])\n",
    "            weight_list.append(weight)\n",
    "\n",
    "    # PyG가 요구하는 텐서 형태로 변환\n",
    "    # edge_index: [2, num_edges] 형태의 LongTensor\n",
    "    edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # edge_attr: [num_edges, 1] 형태의 FloatTensor\n",
    "    edge_attr = torch.tensor(weight_list, dtype=torch.float).view(-1, 1)\n",
    "    \n",
    "    # node_features: [num_nodes, 1] 형태, 각 노드의 ID를 특징으로 사용\n",
    "    node_features = torch.arange(num_nodes, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "    graph_data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    return graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b54414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_weighted_item_transition_graph(train_sequence_file: str) -> Data:\n",
    "    \"\"\"\n",
    "    아이템 시퀀스 데이터로부터 가중치가 있는 아이템 관계 그래프(WITG)를 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        train_sequence_file (str): 학습 데이터로 사용할 시퀀스 파일 경로.\n",
    "\n",
    "    Returns:\n",
    "        Data: 완성된 가중치 그래프의 PyG Data 객체.\n",
    "    \"\"\"\n",
    "    user_sequences, num_nodes = read_item_sequences(train_sequence_file)\n",
    "    \n",
    "    # 인접 리스트: adj[i]는 아이템 i와 연결된 (이웃 아이템, 가중치) 딕셔너리\n",
    "    adjacency_list: List[Dict[int, float]] = [dict() for _ in range(num_nodes)]\n",
    "\n",
    "    # 모든 사용자의 행동 시퀀스를 순회\n",
    "    for sequence in user_sequences:\n",
    "        # 한 시퀀스 내에서 아이템 쌍을 추출 (윈도우 사이즈: 1, 2, 3)\n",
    "        for window_size in range(1, 4):\n",
    "            for i in range(len(sequence) - window_size):\n",
    "    # ======================= TODO: 이 부분을 구현하세요 ========================= #\n",
    "                source_item = sequence[i]\n",
    "                target_item = sequence[i + window_size]\n",
    "                \n",
    "                # 가중치는 거리(window_size)의 역수: 가까울수록 높은 가중치\n",
    "                weight = 1.0 / window_size\n",
    "                \n",
    "                # 양방향(undirected)으로 엣지 가중치를 더해줌\n",
    "                # .get(key, 0.0)은 키가 없으면 0.0을 반환하여 KeyError 방지\n",
    "                adjacency_list[source_item][target_item] = adjacency_list[source_item].get(target_item, 0.0) + weight\n",
    "                adjacency_list[target_item][source_item] = adjacency_list[target_item].get(source_item, 0.0) + weight\n",
    "    # =========================================================================== #\n",
    "    \n",
    "    # 완성된 인접 리스트를 PyG 데이터 객체로 변환\n",
    "    graph_data: Data = convert_to_pyg_data(adjacency_list, num_nodes)\n",
    "    return graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0053ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading WITG from ./dataset/witg.pt\n",
      "WITG structure       : Data(x=[28238, 1], edge_index=[2, 1617638], edge_attr=[1617638, 1])\n",
      "Answer WITG structure: Data(x=[28238, 1], edge_index=[2, 1617638], edge_attr=[1617638, 1])\n",
      "\n",
      "--- WITG SANITY CHECK ---\n",
      "Number of nodes: Match (28238)\n",
      "Edge connectivity structure: Match\n",
      "Edge weights: Match\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(witg_file):\n",
    "    print(f'Loading WITG from {witg_file}')\n",
    "    global_graph = torch.load(witg_file, weights_only=False)\n",
    "else:\n",
    "    print(f'Building WITG and saving to {witg_file}')\n",
    "    global_graph = build_weighted_item_transition_graph(train_sequence_file=train_sequence_file)\n",
    "    torch.save(global_graph, witg_file)\n",
    "\n",
    "\n",
    "# 만든 WITG를 정답 WITG와 비교합니다.\n",
    "answer_witg = torch.load('./dataset/answer_witg.pt', weights_only=False)\n",
    "print(f\"WITG structure       : {global_graph}\")\n",
    "print(f\"Answer WITG structure: {answer_witg}\")\n",
    "grade_witg(student_graph=global_graph, answer_graph=answer_witg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faa8b73",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3662ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위클리 미션 임을 감안하여, epoch는 1로 설정하여 테스트합니다.\n",
    "# 결과 비교를 위해서, 하이퍼 파라미터는 조정하지 않아야 합니다!\n",
    "epochs = 1  \n",
    "batch_size = 2048\n",
    "hidden_size = 64\n",
    "max_seq_length = 50\n",
    "num_hidden_layers = 2\n",
    "num_attention_heads = 2\n",
    "sample_size = [20, 20]\n",
    "lam1 = 1.0\n",
    "lam2 = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274361f9",
   "metadata": {},
   "source": [
    "### [TODO2] Metric 구현하기\n",
    "추천 시스템에서 가장 많이 사용되는, Recall@k와 NDCG@k를 구현해주세요. 두 metric의 수식은 아래과 같습니다.  \n",
    "\n",
    "$Recall@k = \\frac{\\text{Number of recommended items in top-k that are relevant}}{\\text{Total number of relevant items}}$\n",
    "\n",
    "$NDCG@k = \\frac{DCG@k}{IDCG@k}$\n",
    "\n",
    "$DCG@k = \\sum_{i=1}^{k} \\frac{rel_i}{\\log_2(i+1)}$\n",
    "\n",
    "$rel_i$는 $i$번째 위치에 있는 아이템의 **관련성(relevance)**입니다.  \n",
    "일반적으로 해당 아이템이 **정답(target) 아이템**인 경우 **1**이고, 그렇지 않은 경우 **0**입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "016d80b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(actual: List[list], predicted: List[list], topk: int) -> float:\n",
    "    \"\"\"\n",
    "    추천 시스템의 평균 Recall@k를 계산합니다.\n",
    "\n",
    "    Recall@k는 사용자가 실제로 관심 있었던 전체 아이템 중에서,\n",
    "    모델이 추천한 상위 K개의 아이템이 얼마나 포함하고 있는지를 나타내는 지표입니다.\n",
    "\n",
    "    Args:\n",
    "        actual (List[list]): 사용자별 실제 정답 아이템 목록.\n",
    "                             e.g., [[1, 2, 3], [4, 5]]\n",
    "        predicted (List[list]): 모델이 추천한 사용자별 아이템 목록 (점수 순으로 정렬됨).\n",
    "                                e.g., [[1, 5, 2], [4, 8, 9]]\n",
    "        topk (int): 평가에 사용할 상위 K개의 추천 개수.\n",
    "\n",
    "    Returns:\n",
    "        float: 모든 사용자의 Recall@k 점수를 산술 평균한 값.\n",
    "    \"\"\"\n",
    "    total_recall_score = 0.0\n",
    "    num_evaluated_users = 0  # 평가가 가능한 사용자(정답 아이템이 있는) 수\n",
    "\n",
    "    # ============================== TODO: 이 부분을 구현하세요 ================================ #\n",
    "    # 모든 사용자에 대해 반복\n",
    "    for user_id in range(len(predicted)):\n",
    "        ground_truth_items: Set[int] = set(actual[user_id])\n",
    "        \n",
    "        # 평가를 위해선 사용자의 정답 아이템이 최소 1개 이상이어야 함\n",
    "        if not ground_truth_items:\n",
    "            continue\n",
    "            \n",
    "        num_evaluated_users += 1\n",
    "        \n",
    "        # 모델이 추천한 상위 topk개의 아이템 목록\n",
    "        recommended_items: Set[int] = set(predicted[user_id][:topk])\n",
    "        \n",
    "        # 추천된 아이템 중 정답 아이템의 개수 (적중 개수)\n",
    "        num_hits = len(ground_truth_items.intersection(recommended_items))\n",
    "        \n",
    "        # 현재 사용자의 Recall@k 점수 계산: (적중 개수) / (전체 정답 개수)\n",
    "        recall_score = num_hits / len(ground_truth_items)\n",
    "        total_recall_score += recall_score\n",
    "    # ======================================================================================= #\n",
    "    \n",
    "    # 평가된 모든 사용자의 점수를 평균내어 최종 점수 계산\n",
    "    mean_recall = total_recall_score / num_evaluated_users if num_evaluated_users > 0 else 0.0\n",
    "    return mean_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b1b16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_idcg(k: int) -> float:\n",
    "    \"\"\"\n",
    "    IDCG@k (Ideal Discounted Cumulative Gain) 값을 계산하는 헬퍼(helper) 함수.\n",
    "    가장 이상적인 추천, 즉 상위 k개의 아이템이 모두 정답이라고 가정했을 때의 DCG 점수입니다.\n",
    "\n",
    "    Args:\n",
    "        k (int): IDCG를 계산할 목록의 길이.\n",
    "\n",
    "    Returns:\n",
    "        float: IDCG@k 점수.\n",
    "    \"\"\"\n",
    "    ideal_dcg = sum([1.0 / math.log2(rank + 1) for rank in range(1, k + 1)])\n",
    "    return ideal_dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5098fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(actual: List[list], predicted: List[list], topk: int) -> float:\n",
    "    \"\"\"\n",
    "    추천 시스템의 평균 NDCG@k를 계산합니다.\n",
    "\n",
    "    NDCG@k는 추천 결과의 순서까지 고려하는 정밀한 평가 지표입니다.\n",
    "    정답 아이템이 추천 목록의 앞쪽에 있을수록 높은 점수를 받습니다.\n",
    "\n",
    "    Args:\n",
    "        actual (List[list]): 사용자별 실제 정답 아이템 목록.\n",
    "        predicted (List[list]): 모델이 추천한 사용자별 아이템 목록 (점수 순으로 정렬됨).\n",
    "        topk (int): 평가에 사용할 상위 K개의 추천 개수.\n",
    "\n",
    "    Returns:\n",
    "        float: 모든 사용자의 NDCG@k 점수를 산술 평균한 값.\n",
    "    \"\"\"\n",
    "    total_ndcg_score = 0.0\n",
    "    num_evaluated_users = 0  # 평가가 가능한 사용자 수\n",
    "    # ============================== TODO: 이 부분을 구현하세요 ================================ #\n",
    "    for user_id in range(len(predicted)):\n",
    "        ground_truth_items: Set[int] = set(actual[user_id])\n",
    "        \n",
    "        if not ground_truth_items:\n",
    "            continue\n",
    "            \n",
    "        num_evaluated_users += 1\n",
    "        \n",
    "        # 1. DCG@k (Discounted Cumulative Gain) 계산\n",
    "        dcg_score = 0.0\n",
    "        # 추천 순위(rank)는 1부터 시작\n",
    "        for rank, item_id in enumerate(predicted[user_id][:topk], 1):\n",
    "            # 추천한 아이템이 정답 목록에 있다면, 순위에 따라 점수를 할인하여 더함\n",
    "            if item_id in ground_truth_items:\n",
    "                dcg_score += 1.0 / math.log2(rank + 1)\n",
    "        \n",
    "        # 2. IDCG@k (Ideal DCG) 계산 (가장 이상적인 추천일 경우의 DCG 값)\n",
    "        idcg_score = _calculate_idcg(min(topk, len(ground_truth_items)))\n",
    "        \n",
    "        # 3. NDCG@k 계산 및 누적 (0으로 나누는 경우 방지)\n",
    "        if idcg_score > 0:\n",
    "            ndcg_score = dcg_score / idcg_score\n",
    "            total_ndcg_score += ndcg_score\n",
    "    # ======================================================================================= #\n",
    "    mean_ndcg = total_ndcg_score / num_evaluated_users if num_evaluated_users > 0 else 0.0\n",
    "    return mean_ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf1c66b",
   "metadata": {},
   "source": [
    "### Trainer 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dbcab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, sample_size, hidden_size, train_matrix):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.sample_size = sample_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.train_matrix = train_matrix\n",
    "        self.model.to(self.model.device)\n",
    "\n",
    "    def get_scores(self, answers, pred_list):\n",
    "        recall_10 = recall_at_k(answers, pred_list, 10)\n",
    "        recall_20 = recall_at_k(answers, pred_list, 20)\n",
    "        ndcg_10 = ndcg_at_k(answers, pred_list, 10)\n",
    "        ndcg_20 = ndcg_at_k(answers, pred_list, 20)\n",
    "        return recall_10, recall_20, ndcg_10, ndcg_20\n",
    "\n",
    "    def predict(self, seq_out):\n",
    "        test_item_emb = self.model.item_embeddings.weight\n",
    "        rating_pred = torch.matmul(seq_out, test_item_emb.transpose(0, 1))\n",
    "        return rating_pred\n",
    "\n",
    "    def train_step(self, epoch, train_dataloader):\n",
    "        self.model.train()\n",
    "        main_loss_sum = 0.0\n",
    "        gcl_loss_sum = 0.0\n",
    "        mmd_loss_sum = 0.0\n",
    "\n",
    "        for _, batch in tqdm(enumerate(train_dataloader), desc=f\"Epoch {epoch}\", total=len(train_dataloader)):\n",
    "            batch = tuple(t.to(self.model.device) for t in batch)\n",
    "            loss, main_loss, gcl_loss, mmd_loss = self.model.calculate_loss(batch)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            main_loss_sum += main_loss.item()\n",
    "            gcl_loss_sum += gcl_loss.item()\n",
    "            mmd_loss_sum += mmd_loss.item()\n",
    "\n",
    "        main_loss_avg = main_loss_sum / len(train_dataloader)\n",
    "        gcl_loss_avg = gcl_loss_sum / len(train_dataloader)\n",
    "        mmd_loss_avg = mmd_loss_sum / len(train_dataloader)\n",
    "\n",
    "        return main_loss_avg, gcl_loss_avg, mmd_loss_avg\n",
    "\n",
    "    def eval_step(self, dataloader, test_matrix):\n",
    "        self.model.eval()\n",
    "        pred_list = None\n",
    "        answer_list = None\n",
    "\n",
    "        for i, batch in tqdm(enumerate(dataloader), desc=\"Evaluate\", total=len(dataloader)):\n",
    "            batch = tuple(t.to(self.model.device) for t in batch)\n",
    "            user_ids = batch[0]\n",
    "            answers = batch[2]\n",
    "            recommend_output = self.model.eval_stage(batch)\n",
    "            answers = answers.view(-1, 1)\n",
    "\n",
    "            rating_pred = self.predict(recommend_output)\n",
    "            rating_pred = rating_pred.cpu().data.numpy().copy()\n",
    "            batch_user_index = user_ids.cpu().numpy()\n",
    "            rating_pred[test_matrix[batch_user_index].toarray() > 0] = 0\n",
    "            ind = np.argpartition(rating_pred, -20)[:, -20:]\n",
    "            arr_ind = rating_pred[np.arange(len(rating_pred))[:, None], ind]\n",
    "            arr_ind_argsort = np.argsort(arr_ind)[np.arange(len(rating_pred)), ::-1]\n",
    "            batch_pred_list = ind[np.arange(len(rating_pred))[:, None], arr_ind_argsort]\n",
    "\n",
    "            if i == 0:\n",
    "                pred_list = batch_pred_list\n",
    "                answer_list = answers.cpu().data.numpy()\n",
    "            else:\n",
    "                pred_list = np.append(pred_list, batch_pred_list, axis=0)\n",
    "                answer_list = np.append(answer_list, answers.cpu().data.numpy(), axis=0)\n",
    "\n",
    "        recall_10, recall_20, ndcg_10, ndcg_20 = self.get_scores(answer_list, pred_list)\n",
    "        return recall_10, recall_20, ndcg_10, ndcg_20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c912fc1f",
   "metadata": {},
   "source": [
    "### [TODO3] Model 구현하기\n",
    "\n",
    "여기서는 논문에서 나온 Maximum Mean Discrepancy (MMD) loss를 구현할 것입니다.  \n",
    "가우시안 커널을 정의한 `gaussian_kernel` 함수의 입출력을 면밀히 살펴보신 다음,  \n",
    "아래의 MMD loss의 정의에 따라서 `MMD_Loss`를 구현해주시면 됩니다.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6c56c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_Encoder(Module):\n",
    "    def __init__(self, hidden_size, sample_size, gnn_dropout_prob):\n",
    "        super(GNN_Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        in_channels = hidden_channels = self.hidden_size\n",
    "        self.num_layers = len(sample_size)\n",
    "        self.dropout = nn.Dropout(gnn_dropout_prob)\n",
    "        self.gcn = GCNConv(self.hidden_size, self.hidden_size)\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels, normalize=True))\n",
    "        for i in range(self.num_layers - 1):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels, normalize=True))\n",
    "\n",
    "\n",
    "    def forward(self, x, adjs, attr):\n",
    "        xs = []\n",
    "        x_all = x\n",
    "        if self.num_layers > 1:\n",
    "            for i, (edge_index, e_id, size) in enumerate(adjs):\n",
    "                weight = attr[e_id].view(-1).type(torch.float)\n",
    "\n",
    "                x = x_all\n",
    "                if len(list(x.shape)) < 2:\n",
    "                    x = x.unsqueeze(0)\n",
    "                x = self.gcn(x, edge_index, weight)\n",
    "                # sage\n",
    "                x_target = x[:size[1]]  # Target nodes are always placed first.\n",
    "                x = self.convs[i]((x, x_target), edge_index)\n",
    "                if i != self.num_layers - 1:\n",
    "                    x = F.relu(x)\n",
    "                    x = self.dropout(x)\n",
    "        else:\n",
    "            edge_index, e_id, size = adjs.edge_index, adjs.e_id, adjs.size\n",
    "            x = x_all\n",
    "            x = self.dropout(x)\n",
    "            weight = attr[e_id].view(-1).type(torch.float)\n",
    "            if len(list(x.shape)) < 2:\n",
    "                x = x.unsqueeze(0)\n",
    "            x = self.gcn(x, edge_index, weight)\n",
    "            x_target = x[:size[1]]  # Target nodes are always placed first.\n",
    "            x = self.convs[-1]((x, x_target), edge_index)\n",
    "        xs.append(x)\n",
    "        return torch.cat(xs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c10eb0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCL4SR(nn.Module):\n",
    "    def __init__(self, user_num, item_num, hidden_size, max_seq_length, num_attention_heads, global_graph, num_hidden_layers, lam1, lam2, sample_size):\n",
    "        super(GCL4SR, self).__init__()\n",
    "\n",
    "        self.user_num = user_num\n",
    "        self.item_num = item_num\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sample_size = sample_size\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.lam1 = lam1\n",
    "        self.lam2 = lam2\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        \n",
    "        self.global_graph = global_graph.to(self.device)\n",
    "        self.global_gnn = GNN_Encoder(hidden_size, sample_size, gnn_dropout_prob=0.5)\n",
    "\n",
    "        self.user_embeddings = nn.Embedding(user_num, hidden_size)\n",
    "        self.item_embeddings = nn.Embedding(item_num, hidden_size, padding_idx=0)\n",
    "        self.position_embeddings = nn.Embedding(max_seq_length, hidden_size)\n",
    "\n",
    "        # sequence encoder\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_size,\n",
    "                                                        nhead=num_attention_heads,\n",
    "                                                        dim_feedforward=4 * hidden_size,\n",
    "                                                        dropout=0.5,\n",
    "                                                        activation='gelu',\n",
    "                                                        batch_first=True)\n",
    "        \n",
    "        self.item_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_hidden_layers)\n",
    "\n",
    "        # AttNet\n",
    "        self.w_1 = nn.Parameter(torch.Tensor(2*hidden_size, hidden_size))\n",
    "        self.w_2 = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
    "        self.linear_1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear_2 = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "\n",
    "        self.w_g = nn.Linear(hidden_size, 1)\n",
    "        self.w_e = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        self.LayerNorm = nn.LayerNorm(hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear_transform = nn.Linear(3*hidden_size, hidden_size, bias=False)\n",
    "        self.gnndrop = nn.Dropout(0.5)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "        # user-specific gating\n",
    "        self.gate_item = Variable(torch.zeros(hidden_size, 1).type\n",
    "                                  (torch.FloatTensor), requires_grad=True).to(self.device)\n",
    "        self.gate_user = Variable(torch.zeros(hidden_size, max_seq_length).type\n",
    "                                  (torch.FloatTensor), requires_grad=True).to(self.device)\n",
    "        self.gate_item = torch.nn.init.xavier_uniform_(self.gate_item)\n",
    "        self.gate_user = torch.nn.init.xavier_uniform_(self.gate_user)\n",
    "\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            xavier_normal_(module.weight.data)\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            xavier_normal_(module.weight.data)\n",
    "            if module.bias is not None:\n",
    "                constant_(module.bias.data, 0)\n",
    "\n",
    "\n",
    "    def gnn_encode(self, items):\n",
    "        subgraph_loaders = NeighborSampler(self.global_graph.edge_index, node_idx=items, sizes=self.sample_size,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=0, batch_size=items.shape[0])\n",
    "        g_adjs = []\n",
    "        s_nodes = []\n",
    "        for (b_size, node_idx, adjs) in subgraph_loaders:\n",
    "            if type(adjs) == list:\n",
    "                g_adjs = [adj.to(items.device) for adj in adjs]\n",
    "            else:\n",
    "                g_adjs = adjs.to(items.device)\n",
    "            n_idxs = node_idx.to(items.device)\n",
    "            s_nodes = self.item_embeddings(n_idxs).squeeze()\n",
    "        attr = self.global_graph.edge_attr.to(items.device)\n",
    "        g_hidden = self.global_gnn(s_nodes, g_adjs, attr)\n",
    "        return g_hidden\n",
    "\n",
    "\n",
    "    def final_att_net(self, seq_mask, hidden):\n",
    "        batch_size = hidden.shape[0]\n",
    "        lens = hidden.shape[1]\n",
    "        pos_emb = self.position_embeddings.weight[:lens]\n",
    "        pos_emb = pos_emb.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        seq_hidden = torch.sum(hidden * seq_mask, -2) / torch.sum(seq_mask, 1)\n",
    "        seq_hidden = seq_hidden.unsqueeze(-2).repeat(1, lens, 1)\n",
    "        item_hidden = torch.matmul(torch.cat([pos_emb, hidden], -1), self.w_1)\n",
    "        item_hidden = torch.tanh(item_hidden)\n",
    "        score = torch.sigmoid(self.linear_1(item_hidden) + self.linear_2(seq_hidden))\n",
    "        att_score = torch.matmul(score, self.w_2)\n",
    "        att_score_masked = att_score * seq_mask\n",
    "        output = torch.sum(att_score_masked * hidden, 1)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz: int) -> Tensor:\n",
    "        mask = torch.triu(torch.ones(sz, sz, dtype=torch.bool), diagonal=1)\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        user_ids = data[0]\n",
    "        inputs = data[1]\n",
    "\n",
    "        seq = inputs.flatten()\n",
    "        seq_mask = (inputs == 0).float().unsqueeze(-1)\n",
    "        seq_mask = 1.0 - seq_mask\n",
    "\n",
    "        seq_hidden_global_a = self.gnn_encode(seq).view(-1, self.max_seq_length, self.hidden_size)\n",
    "        seq_hidden_global_b = self.gnn_encode(seq).view(-1, self.max_seq_length, self.hidden_size)\n",
    "\n",
    "        key_padding_mask = (inputs == 0)\n",
    "        attn_mask = self.generate_square_subsequent_mask(self.max_seq_length).to(inputs.device)\n",
    "        seq_hidden_local = self.item_embeddings(inputs)\n",
    "        seq_hidden_local = self.LayerNorm(seq_hidden_local)\n",
    "        seq_hidden_local = self.dropout(seq_hidden_local)\n",
    "\n",
    "        seq_hidden_permute = seq_hidden_local\n",
    "        encoded_layers = self.item_encoder(seq_hidden_permute,\n",
    "                                           mask=attn_mask,\n",
    "                                           src_key_padding_mask=key_padding_mask)\n",
    "        sequence_output = encoded_layers\n",
    "\n",
    "        user_emb = self.user_embeddings(user_ids).view(-1, self.hidden_size)\n",
    "\n",
    "        gating_score_a = torch.sigmoid(torch.matmul(seq_hidden_global_a, self.gate_item.unsqueeze(0)).squeeze() +\n",
    "                                       user_emb.mm(self.gate_user))\n",
    "        user_seq_a = seq_hidden_global_a * gating_score_a.unsqueeze(2)\n",
    "        gating_score_b = torch.sigmoid(torch.matmul(seq_hidden_global_b, self.gate_item.unsqueeze(0)).squeeze() +\n",
    "                                       user_emb.mm(self.gate_user))\n",
    "        user_seq_b = seq_hidden_global_b * gating_score_b.unsqueeze(2)\n",
    "\n",
    "        user_seq_a = self.gnndrop(user_seq_a)\n",
    "        user_seq_b = self.gnndrop(user_seq_b)\n",
    "\n",
    "        hidden = torch.cat([sequence_output, user_seq_a, user_seq_b], -1)\n",
    "        hidden = self.linear_transform(hidden)\n",
    "\n",
    "        return sequence_output, hidden, user_seq_a, user_seq_b, (seq_hidden_global_a, seq_hidden_global_b), seq_mask\n",
    "\n",
    "\n",
    "    def eval_stage(self, data):\n",
    "        _, hidden, _, _, _, seq_mask = self.forward(data)\n",
    "        hidden = self.final_att_net(seq_mask, hidden)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "    def calculate_loss(self, data):\n",
    "        targets = data[2]\n",
    "        sequence_output, hidden, user_seq_a, user_seq_b, (seq_gnn_a, seq_gnn_b), seq_mask = self.forward(data)\n",
    "        seq_out = self.final_att_net(seq_mask, hidden)\n",
    "        seq_out = self.dropout(seq_out)\n",
    "        test_item_emb = self.item_embeddings.weight[:self.item_num]\n",
    "        logits = torch.matmul(seq_out, test_item_emb.transpose(0, 1))\n",
    "        main_loss = self.criterion(logits, targets)\n",
    "\n",
    "        sum_a = torch.sum(seq_gnn_a * seq_mask, 1) / torch.sum(seq_mask.float(), 1)\n",
    "        sum_b = torch.sum(seq_gnn_b * seq_mask, 1) / torch.sum(seq_mask.float(), 1)\n",
    "\n",
    "        info_hidden = torch.cat([sum_a, sum_b], 0)\n",
    "        gcl_loss = self.GCL_loss(info_hidden, hidden_norm=True, temperature=0.5)\n",
    "\n",
    "        seq_hidden_local = self.w_e(self.item_embeddings(data[1])).squeeze().unsqueeze(0)\n",
    "        user_seq_a = self.w_g(user_seq_a).squeeze()\n",
    "        user_seq_b = self.w_g(user_seq_b).squeeze()\n",
    "        mmd_loss = self.MMD_loss(seq_hidden_local, user_seq_a) + self.MMD_loss(seq_hidden_local, user_seq_b)\n",
    "\n",
    "        loss = main_loss + self.lam1 * gcl_loss + self.lam2 * mmd_loss\n",
    "        return loss, main_loss, gcl_loss, mmd_loss\n",
    "    \n",
    "\n",
    "    def GCL_loss(self, hidden, hidden_norm=True, temperature=1.0):\n",
    "        batch_size = hidden.shape[0] // 2\n",
    "        LARGE_NUM = 1e9\n",
    "        if hidden_norm:\n",
    "            hidden = torch.nn.functional.normalize(hidden, p=2, dim=-1)\n",
    "        hidden_list = torch.split(hidden, batch_size, dim=0)\n",
    "        hidden1, hidden2 = hidden_list[0], hidden_list[1]\n",
    "\n",
    "        hidden1_large = hidden1\n",
    "        hidden2_large = hidden2\n",
    "        labels = torch.from_numpy(np.arange(batch_size)).to(hidden.device)\n",
    "        masks = torch.nn.functional.one_hot(torch.from_numpy(np.arange(batch_size)).to(hidden.device), batch_size)\n",
    "\n",
    "        logits_aa = torch.matmul(hidden1, hidden1_large.transpose(1, 0)) / temperature\n",
    "        logits_aa = logits_aa - masks * LARGE_NUM\n",
    "        logits_bb = torch.matmul(hidden2, hidden2_large.transpose(1, 0)) / temperature\n",
    "        logits_bb = logits_bb - masks * LARGE_NUM\n",
    "        logits_ab = torch.matmul(hidden1, hidden2_large.transpose(1, 0)) / temperature\n",
    "        logits_ba = torch.matmul(hidden2, hidden1_large.transpose(1, 0)) / temperature\n",
    "\n",
    "        loss_a = torch.nn.functional.cross_entropy(torch.cat([logits_ab, logits_aa], 1), labels)\n",
    "        loss_b = torch.nn.functional.cross_entropy(torch.cat([logits_ba, logits_bb], 1), labels)\n",
    "        loss = (loss_a + loss_b)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    # def MMD_loss(self, source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    #     source = source.view(-1, self.max_seq_length)\n",
    "    #     target = target.view(-1, self.max_seq_length)\n",
    "    #     batch_size = int(source.size()[0])\n",
    "    #     loss_all = []\n",
    "    #     kernels = self.gaussian_kernel(source, target, kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n",
    "    #     xx = kernels[:batch_size, :batch_size]\n",
    "    #     yy = kernels[batch_size:, batch_size:]\n",
    "    #     xy = kernels[:batch_size, batch_size:]\n",
    "    #     yx = kernels[batch_size:, :batch_size]\n",
    "    #     loss = torch.mean(xx + yy - xy - yx)\n",
    "    #     loss_all.append(loss)\n",
    "    #     return sum(loss_all) / len(loss_all)\n",
    "\n",
    "\n",
    "    def gaussian_kernel(self, source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "        \"\"\"\n",
    "        두 데이터 집합(source, target) 간의 가우시안 커널 값을 계산합니다.\n",
    "        MMD Loss 계산에 사용되는 핵심 함수입니다.\n",
    "        여러 개의 커널을 혼합하여 사용하는 Multi-kernel 방식을 적용합니다.\n",
    "\n",
    "        Args:\n",
    "            source (torch.Tensor): 첫 번째 분포의 샘플 텐서.\n",
    "                                   Shape: (batch_size, feature_dim)\n",
    "            target (torch.Tensor): 두 번째 분포의 샘플 텐서.\n",
    "                                   Shape: (batch_size, feature_dim)\n",
    "            kernel_mul (float): 다양한 대역폭(bandwidth)을 만들기 위한 배수.\n",
    "                                기본값은 2.0입니다.\n",
    "            kernel_num (int): 사용할 커널의 개수. 기본값은 5입니다.\n",
    "            fix_sigma (float, optional): 대역폭(sigma) 값을 고정할 경우 사용.\n",
    "                                         None일 경우, 데이터로부터 동적으로 계산됩니다.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 계산된 가우시안 커널 행렬.\n",
    "                          Shape: (2 * batch_size, 2 * batch_size)\n",
    "        \"\"\"\n",
    "        # source와 target 텐서를 합쳐 전체 샘플 수를 계산합니다.\n",
    "        n_samples = int(source.size()[0]) + int(target.size()[0])\n",
    "        \n",
    "        # 두 텐서를 concat하여 하나의 텐서로 만듭니다.\n",
    "        total = torch.cat([source, target], dim=0)\n",
    "\n",
    "        # 모든 샘플 쌍 간의 L2 거리의 제곱을 효율적으로 계산합니다.\n",
    "        # total.unsqueeze(0) -> (1, n_samples, feature_dim)\n",
    "        # total.unsqueeze(1) -> (n_samples, 1, feature_dim)\n",
    "        # 브로드캐스팅을 통해 (n_samples, n_samples, feature_dim) 크기의 텐서 2개를 만듭니다.\n",
    "        total0 = total.unsqueeze(0).expand(n_samples, n_samples, total.size(1))\n",
    "        total1 = total.unsqueeze(1).expand(n_samples, n_samples, total.size(1))\n",
    "        # 각 샘플 쌍의 거리 제곱을 계산하고, feature 차원에 대해 합산합니다.\n",
    "        L2_distance = ((total0 - total1) ** 2).sum(2)\n",
    "\n",
    "        # 대역폭(bandwidth) 값을 설정합니다.\n",
    "        if fix_sigma:\n",
    "            bandwidth = fix_sigma\n",
    "        else:\n",
    "            # 모든 샘플 쌍 간 거리의 평균값을 기반으로 대역폭을 추정합니다.\n",
    "            bandwidth = torch.sum(L2_distance.data) / (n_samples ** 2 - n_samples)\n",
    "\n",
    "        # Multi-kernel 방식을 위해 여러 대역폭 값을 생성합니다.\n",
    "        # 기본 대역폭 값에 kernel_mul을 거듭제곱하여 곱해줍니다.\n",
    "        bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "        bandwidth_list = [bandwidth * (kernel_mul ** i) for i in range(kernel_num)]\n",
    "\n",
    "        # 각 대역폭에 대해 가우시안 커널 값을 계산합니다.\n",
    "        # K(x, y) = exp(-||x - y||^2 / (2 * sigma^2))\n",
    "        # 여기서 bandwidth는 2 * sigma^2에 해당합니다.\n",
    "        kernel_val = [torch.exp(-L2_distance / bw) for bw in bandwidth_list]\n",
    "        \n",
    "        # 계산된 모든 커널 값을 합산하여 최종 커널 행렬을 반환합니다.\n",
    "        return sum(kernel_val)\n",
    "\n",
    "\n",
    "    def MMD_loss(self, source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "        \"\"\"\n",
    "        두 분포 간의 최대 평균 불일치(Maximum Mean Discrepancy, MMD) 손실을 계산합니다.\n",
    "        MMD는 두 분포가 얼마나 다른지를 측정하는 지표입니다.\n",
    "\n",
    "        Args:\n",
    "            source (torch.Tensor): 첫 번째 분포(e.g., 로컬 정보)의 샘플 텐서.\n",
    "                                   Shape: (batch_size, seq_len, feature_dim) 또는 (batch_size, feature_dim)\n",
    "            target (torch.Tensor): 두 번째 분포(e.g., 글로벌 정보)의 샘플 텐서.\n",
    "                                   Shape: (batch_size, seq_len, feature_dim) 또는 (batch_size, feature_dim)\n",
    "            kernel_mul (float): gaussian_kernel 함수로 전달될 인수.\n",
    "            kernel_num (int): gaussian_kernel 함수로 전달될 인수.\n",
    "            fix_sigma (float, optional): gaussian_kernel 함수로 전달될 인수.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 계산된 MMD 손실 값 (스칼라 텐서).\n",
    "        \"\"\"\n",
    "        # 입력 텐서들을 (batch_size, max_seq_length) 형태로 변환합니다.\n",
    "        source = source.view(-1, self.max_seq_length)\n",
    "        target = target.view(-1, self.max_seq_length)\n",
    "        \n",
    "        batch_size = int(source.size()[0])\n",
    "        \n",
    "        # gaussian_kernel 함수를 호출하여 커널 행렬을 얻습니다.\n",
    "        # 이 행렬은 source와 target 샘플 간의 모든 쌍에 대한 커널 값을 포함합니다.\n",
    "        kernels = self.gaussian_kernel(source, target,\n",
    "                                       kernel_mul=kernel_mul,\n",
    "                                       kernel_num=kernel_num,\n",
    "                                       fix_sigma=fix_sigma)\n",
    "\n",
    "        # 커널 행렬을 4개의 부분 행렬로 분할합니다.\n",
    "        # XX: source 내부 샘플 간의 커널 값\n",
    "        xx = kernels[:batch_size, :batch_size]\n",
    "        # YY: target 내부 샘플 간의 커널 값\n",
    "        yy = kernels[batch_size:, batch_size:]\n",
    "        # XY: source와 target 샘플 간의 커널 값\n",
    "        xy = kernels[:batch_size, batch_size:]\n",
    "        # YX: target과 source 샘플 간의 커널 값\n",
    "        yx = kernels[batch_size:, :batch_size]\n",
    "\n",
    "        # MMD loss를 계산합니다.\n",
    "        # MMD^2 = E[K(x, x')] + E[K(y, y')] - 2 * E[K(x, y)]\n",
    "        # 위 식을 샘플 평균으로 근사한 것입니다.\n",
    "        loss = torch.mean(xx + yy - xy - yx)\n",
    "        \n",
    "        # 계산된 손실 값을 반환합니다.\n",
    "        # (loss_all 리스트는 현재 코드에서는 불필요해 보이지만 원본 로직을 유지했습니다.)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7da8500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCL4SR(\n",
    "    user_num=user_num,\n",
    "    item_num=item_num,\n",
    "    global_graph=global_graph,\n",
    "    hidden_size=hidden_size,\n",
    "    max_seq_length=max_seq_length,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    num_attention_heads=num_attention_heads,\n",
    "    sample_size=sample_size,\n",
    "    lam1=lam1,\n",
    "    lam2=lam2\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffb8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위클리 미션 임을 감안하여, Validation 단계는 생략합니다.\n",
    "\n",
    "# valid_dataset = GCL4SRData(valid_data, max_seq_length)\n",
    "# valid_sampler = SequentialSampler(valid_dataset)\n",
    "# valid_dataloader = DataLoader(valid_dataset, sampler=valid_sampler, batch_size=batch_size)\n",
    "\n",
    "train_dataset = GCL4SRData(train_data, max_seq_length)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
    "\n",
    "test_dataset = GCL4SRData(test_data, max_seq_length)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "500822eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, optimizer, sample_size, hidden_size, train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe93663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/GCL4SR/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "0.16s - Expected: /opt/anaconda3/envs/GCL4SR/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd_attach_to_process/attach.dylib to exist.\n",
      "0.13s - Expected: /opt/anaconda3/envs/GCL4SR/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd_attach_to_process/attach.dylib to exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/GCL4SR/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/anaconda3/envs/GCL4SR/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'GCL4SRData' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    loss_list = trainer.train_step(epoch, train_dataloader)\n",
    "    torch.save(model.state_dict(), checkpoint_file)\n",
    "\n",
    "# Loss 값을 비교합니다.\n",
    "grade_loss(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90622f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.load_state_dict(torch.load(checkpoint_file))\n",
    "recall_10, recall_20, ndcg_10, ndcg_20 = trainer.eval_step(test_dataloader, test_matrix)\n",
    "\n",
    "# Evaluation 결과를 비교합니다.\n",
    "grade_eval(recall_10, recall_20, ndcg_10, ndcg_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b0b7b",
   "metadata": {},
   "source": [
    "WARNING: 본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. \n",
    "본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다. \n",
    "다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. \n",
    "이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GCL4SR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
